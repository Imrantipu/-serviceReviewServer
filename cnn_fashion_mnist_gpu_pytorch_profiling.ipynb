{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP82+PawlqF8EoLQqoHcfhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imrantipu/-serviceReviewServer/blob/main/cnn_fashion_mnist_gpu_pytorch_profiling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "F-DJICfb8TD7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqdjPkYY8vy1",
        "outputId": "2c40aa98-47a6-4035-aac7-ac0b765ca460"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b61fab26550>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQw5YZWD8zef",
        "outputId": "c6ab4546-c88e-41ab-b0ac-9c7917d7b6c4"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "try:\n",
        "    df = pd.read_csv(\"fmnist_small.csv\")\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print(f\"Error reading CSV: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DHctUwW85hu",
        "outputId": "64819ec7-fb19-4dc4-e7ec-593f2fd6269f"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
            "0      9       0       0       0       0       0       0       0       0   \n",
            "1      7       0       0       0       0       0       0       0       0   \n",
            "2      0       0       0       0       0       0       1       0       0   \n",
            "3      8       0       0       0       0       0       0       0       0   \n",
            "4      8       0       0       0       0       0       0       0       0   \n",
            "\n",
            "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0       0  ...         0         7         0        50       205       196   \n",
            "1       0  ...         0         0         0         0         0         0   \n",
            "2       0  ...       142       142       142        21         0         3   \n",
            "3       0  ...         0         0         0         0         0         0   \n",
            "4       0  ...       213       203       174       151       188        10   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0       213       165         0         0  \n",
            "1         0         0         0         0  \n",
            "2         0         0         0         0  \n",
            "3         0         0         0         0  \n",
            "4         0         0         0         0  \n",
            "\n",
            "[5 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)  # Print the shape of the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyMr2yt98hE",
        "outputId": "07471b3e-8b4f-4329-9ce2-a5a2d4114e5b"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "ZTZwq8b8Ucy9"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index], self.labels[index]"
      ],
      "metadata": {
        "id": "4BWOHya2-E82"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and dataloaders\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "ZPsaRC_jBLtH"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class MyNN(nn.Module):\n",
        "    def __init__(self, input_features):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_features, 32, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LcXzzutKBinV"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = MyNN(1).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "_eng_dVkBmlb"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with profiling\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],  # Profile both CPU and GPU\n",
        "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),  # Profile 3 steps, repeat twice\n",
        "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./logs'),  # Save logs for TensorBoard\n",
        "    record_shapes=True,\n",
        "    profile_memory=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    for epoch in range(2):  # Run for 2 epochs for profiling\n",
        "        model.train()\n",
        "        for i, (batch_features, batch_labels) in enumerate(train_loader):\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            with record_function(\"forward\"):\n",
        "                outputs = model(batch_features)\n",
        "                loss = criterion(outputs, batch_labels)\n",
        "\n",
        "            # Backward pass\n",
        "            with record_function(\"backward\"):\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "            # Optimizer step\n",
        "            with record_function(\"optimizer_step\"):\n",
        "                optimizer.step()\n",
        "\n",
        "            # Profiler step\n",
        "            prof.step()\n",
        "\n",
        "            if i >= 10:  # Stop after 10 batches for demonstration\n",
        "                break\n",
        "\n",
        "# Print profiling results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5spZ_ZRFWMHY",
        "outputId": "819f8d15-6c9d-435a-9938-292149330058"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                forward         0.00%       0.000us         0.00%       0.000us       0.000us       3.521ms        46.09%       3.521ms       1.174ms           0 b           0 b           0 b           0 b             3  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.41%     101.126us         5.83%       1.446ms     240.968us       0.000us         0.00%       2.498ms     416.330us           0 b           0 b     -30.06 Mb     -35.53 Mb             6  \n",
            "                                   ConvolutionBackward0         0.30%      74.309us         5.42%       1.345ms     224.114us       0.000us         0.00%       2.498ms     416.330us           0 b           0 b       5.47 Mb           0 b             6  \n",
            "                             aten::convolution_backward         2.29%     567.789us         5.12%       1.270ms     211.729us       2.281ms        29.86%       2.498ms     416.330us           0 b           0 b       5.47 Mb       5.25 Mb             6  \n",
            "                               Optimizer.step#Adam.step         0.00%       0.000us         0.00%       0.000us       0.000us       2.084ms        27.28%       2.084ms     694.766us           0 b           0 b           0 b           0 b             3  \n",
            "                                                forward         6.40%       1.586ms        17.16%       4.253ms       1.418ms       0.000us         0.00%       1.959ms     652.837us           0 b           0 b      48.99 Mb     -27.67 Mb             3  \n",
            "autograd::engine::evaluate_function: MaxPool2DWithIn...         0.43%     107.271us         2.27%     562.349us      93.725us       0.000us         0.00%       1.265ms     210.773us           0 b           0 b       5.58 Mb     -21.98 Mb             6  \n",
            "                          MaxPool2DWithIndicesBackward0         0.14%      35.242us         1.84%     455.078us      75.846us       0.000us         0.00%       1.265ms     210.773us           0 b           0 b      27.56 Mb           0 b             6  \n",
            "                 aten::max_pool2d_with_indices_backward         0.51%     127.179us         1.69%     419.836us      69.973us       1.152ms        15.08%       1.265ms     210.773us           0 b           0 b      27.56 Mb      27.56 Mb             6  \n",
            "                                           aten::conv2d         0.11%      28.304us         3.98%     985.922us     164.320us       0.000us         0.00%       1.178ms     196.352us           0 b           0 b      27.56 Mb           0 b             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 24.790ms\n",
            "Self CUDA time total: 7.639ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an improved neural network architecture\n",
        "class MyNN(nn.Module):\n",
        "    def __init__(self, input_features):\n",
        "        super().__init__()\n",
        "        # Feature extraction layers\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_features, 32, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding='same'),  # Additional layer\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Classifier layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 3 * 3, 256),  # Adjusted input size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.4),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.4),\n",
        "\n",
        "            nn.Linear(128, 10)\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "gVfCtaN7Btvx"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "learning_rate = 0.001  # Reduced learning rate\n",
        "epochs = 100  # Increased number of epochs"
      ],
      "metadata": {
        "id": "kD3EmK8uBxYi"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and move it to the device\n",
        "model = MyNN(1)\n",
        "model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer (Adam for better convergence)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# Add a learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR by 0.1 every 5 epochs"
      ],
      "metadata": {
        "id": "CsUBGvJsB1Bu"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with early stopping\n",
        "best_accuracy = 0\n",
        "patience = 3  # Number of epochs to wait before stopping\n",
        "epochs_without_improvement = 0"
      ],
      "metadata": {
        "id": "NiRug8_bL5dB"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_epoch_loss = 0\n",
        "\n",
        "    for batch_features, batch_labels in train_loader:\n",
        "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_features)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_epoch_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = total_epoch_loss / len(train_loader)\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {avg_loss}')\n",
        "\n",
        "    # Evaluation on test data\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_features, batch_labels in test_loader:\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "            outputs = model(batch_features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += batch_labels.shape[0]\n",
        "            correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "    # Early stopping logic\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        epochs_without_improvement = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement >= patience:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15mNdQ2WOuJj",
        "outputId": "5b40337f-debc-466b-ad9f-af1fb1264456"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.9551528696219126\n",
            "Test Accuracy: 0.8208333333333333\n",
            "Epoch: 2, Loss: 0.5063882442315419\n",
            "Test Accuracy: 0.8366666666666667\n",
            "Epoch: 3, Loss: 0.38721385816733045\n",
            "Test Accuracy: 0.8183333333333334\n",
            "Epoch: 4, Loss: 0.325982511639595\n",
            "Test Accuracy: 0.8391666666666666\n",
            "Epoch: 5, Loss: 0.2668511484066645\n",
            "Test Accuracy: 0.8541666666666666\n",
            "Epoch: 6, Loss: 0.162055803835392\n",
            "Test Accuracy: 0.865\n",
            "Epoch: 7, Loss: 0.12905061319470407\n",
            "Test Accuracy: 0.8541666666666666\n",
            "Epoch: 8, Loss: 0.10347860485315323\n",
            "Test Accuracy: 0.8608333333333333\n",
            "Epoch: 9, Loss: 0.09289832554757595\n",
            "Test Accuracy: 0.8591666666666666\n",
            "Early stopping triggered!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on training data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSQmxhMuCC97",
        "outputId": "1a90b804-9782-4b3e-c353-e6aa55c93126"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9860416666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with profiling\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],  # Profile both CPU and GPU\n",
        "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),  # Profile 3 steps, repeat twice\n",
        "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./logs'),  # Save logs for TensorBoard\n",
        "    record_shapes=True,\n",
        "    profile_memory=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    for epoch in range(2):  # Run for 2 epochs for profiling\n",
        "        model.train()\n",
        "        for i, (batch_features, batch_labels) in enumerate(train_loader):\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            with record_function(\"forward\"):\n",
        "                outputs = model(batch_features)\n",
        "                loss = criterion(outputs, batch_labels)\n",
        "\n",
        "            # Backward pass\n",
        "            with record_function(\"backward\"):\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "            # Optimizer step\n",
        "            with record_function(\"optimizer_step\"):\n",
        "                optimizer.step()\n",
        "\n",
        "            # Profiler step\n",
        "            prof.step()\n",
        "\n",
        "            if i >= 10:  # Stop after 10 batches for demonstration\n",
        "                break\n",
        "\n",
        "# Print profiling results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HLzlMV3WswA",
        "outputId": "fa928b05-276e-4890-ffba-42937fbc31ca"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                forward         0.00%       0.000us         0.00%       0.000us       0.000us       8.840ms       134.43%       8.840ms       2.947ms           0 b           0 b           0 b           0 b             3  \n",
            "                               Optimizer.step#Adam.step         0.00%       0.000us         0.00%       0.000us       0.000us       2.627ms        39.95%       2.627ms     875.615us           0 b           0 b           0 b           0 b             3  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.37%     171.703us         5.04%       2.333ms     259.195us       0.000us         0.00%       2.037ms     226.380us           0 b           0 b     -29.03 Mb     -39.05 Mb             9  \n",
            "                                   ConvolutionBackward0         0.23%     105.280us         4.67%       2.161ms     240.117us       0.000us         0.00%       2.037ms     226.380us           0 b           0 b      10.02 Mb           0 b             9  \n",
            "                             aten::convolution_backward         2.10%     970.593us         4.44%       2.056ms     228.419us       1.837ms        27.94%       2.037ms     226.380us           0 b           0 b      10.02 Mb       8.95 Mb             9  \n",
            "                                                forward         7.22%       3.338ms        21.53%       9.958ms       3.319ms       0.000us         0.00%       1.900ms     633.434us           0 b           0 b      90.89 Mb     -34.51 Mb             3  \n",
            "                                           aten::conv2d         0.11%      49.470us         4.27%       1.975ms     219.449us       0.000us         0.00%     895.560us      99.507us           0 b           0 b      34.22 Mb           0 b             9  \n",
            "                                aten::_convolution_mode         0.18%      84.039us         4.16%       1.926ms     213.953us       0.000us         0.00%     895.560us      99.507us           0 b           0 b      34.22 Mb           0 b             9  \n",
            "                                      aten::convolution         0.40%     183.745us         3.98%       1.842ms     204.615us       0.000us         0.00%     895.560us      99.507us           0 b           0 b      34.22 Mb           0 b             9  \n",
            "                                     aten::_convolution         0.39%     178.534us         3.58%       1.658ms     184.199us       0.000us         0.00%     895.560us      99.507us           0 b           0 b      34.22 Mb           0 b             9  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 46.253ms\n",
            "Self CUDA time total: 6.576ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=./logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9WB1LL8erNO",
        "outputId": "258f25f3-26b8-4315-bb8e-27af889a1723"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-15 21:23:30.503297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-15 21:23:30.522611: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-15 21:23:30.528962: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 21:23:30.543272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-15 21:23:31.549952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1739654613.463652   39329 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1739654613.545177   39329 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1739654613.545569   39329 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.17.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "Exception ignored in atexit callback: <function remove_info_file at 0x7ba5d93de9e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/manager.py\", line 252, in remove_info_file\n",
            "    os.unlink(_get_info_file_path())\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    }
  ]
}