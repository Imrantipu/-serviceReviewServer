{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi4S4lIUBmqVVkl4VxZkuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imrantipu/-serviceReviewServer/blob/main/pytorch_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Zv2hbKtZfgSJ"
      },
      "outputs": [],
      "source": [
        "def dy_dx(x):\n",
        "  return 2*x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dy_dx(3)\n",
        "# equation y = x**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB1FNL6kku9z",
        "outputId": "93d8f009-c75a-40db-f45c-b0d3250fe506"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ZZPAa9S5lAIp"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required grad true because of tensor being applicable for derivation\n",
        "x = torch.tensor(3.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "zm6fvuCYliCW"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "y = x**2\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-XiGT2oqL4k",
        "outputId": "e3850280-7b55-4802-c74e-72118407ada3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3., requires_grad=True)\n",
            "tensor(9., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# automatic derivativ means backward propagation\n",
        "# gradient claculated\n",
        "y.backward(retain_graph=True) # set retain_graph=True to keep the graph for a second backward call"
      ],
      "metadata": {
        "id": "Tv_JYnZBrQHA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the derivative values of the tensor\n",
        "# to see the gradient values\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz4dowW3uYDw",
        "outputId": "7b02ac48-930c-4e7e-e947-bd908eb4bacc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for second equations y=x**2 and z=sin(y)\n",
        "import math\n",
        "def dz_dx(x):\n",
        "  return 2*x*math.cos(x**2)"
      ],
      "metadata": {
        "id": "ITmIvsOCyhzO"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dz_dx(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJcEL1LWzqhf",
        "outputId": "349d0c7d-c121-41e7-de76-9b6a3862f869"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.466781571308061"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x**2\n",
        "z = torch.sin(y)\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAUOoPd4z9Ng",
        "outputId": "7d3c8366-239a-4071-f9d2-af380fcf8d61"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3., requires_grad=True)\n",
            "tensor(9., grad_fn=<PowBackward0>)\n",
            "tensor(0.4121, grad_fn=<SinBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward(retain_graph=True)\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM_99Odn1gc4",
        "outputId": "3ce886df-9b08-43eb-ed9a-36205a633851"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-5.4668)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# mamual claculation without using autograd\n",
        "#Inputs\n",
        "x = torch.tensor(6.7) # input feature\n",
        "y = torch.tensor(0.0) # true lebel binary\n",
        "\n",
        "w= torch.tensor(1.0)  #weight\n",
        "b= torch.tensor(0.0)  #bias"
      ],
      "metadata": {
        "id": "GhLPEWClHUcG"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary Cross-Entropy Loss for scalar\n",
        "def binary_cross_entropy_loss(prediction, target):\n",
        "    epsilon = 1e-8  # To prevent log(0)\n",
        "    prediction = torch.clamp(prediction, epsilon, 1 - epsilon)\n",
        "    return -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))"
      ],
      "metadata": {
        "id": "ts-gmoH0Jz9y"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass\n",
        "z = w * x + b  # Weighted sum (linear part)\n",
        "y_pred = torch.sigmoid(z)  # Predicted probability\n",
        "\n",
        "# Compute binary cross-entropy loss\n",
        "loss = binary_cross_entropy_loss(y_pred, y)"
      ],
      "metadata": {
        "id": "yoA3ZcilJ2bs"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmH0pmjaJ-Ve",
        "outputId": "4efeef55-14fa-4c35-abf3-9f31213c6013"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.7012)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivatives:\n",
        "# 1. dL/d(y_pred): Loss with respect to the prediction (y_pred)\n",
        "dloss_dy_pred = (y_pred - y)/(y_pred*(1-y_pred))\n",
        "\n",
        "# 2. dy_pred/dz: Prediction (y_pred) with respect to z (sigmoid derivative)\n",
        "dy_pred_dz = y_pred * (1 - y_pred)\n",
        "\n",
        "# 3. dz/dw and dz/db: z with respect to w and b\n",
        "dz_dw = x  # dz/dw = x\n",
        "dz_db = 1  # dz/db = 1 (bias contributes directly to z)\n",
        "\n",
        "dL_dw = dloss_dy_pred * dy_pred_dz * dz_dw\n",
        "dL_db = dloss_dy_pred * dy_pred_dz * dz_db"
      ],
      "metadata": {
        "id": "eD76ZxG6KDaK"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Manual Gradient of loss w.r.t weight (dw): {dL_dw}\")\n",
        "print(f\"Manual Gradient of loss w.r.t bias (db): {dL_db}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho2mU3-wKKfK",
        "outputId": "0dfd59f6-296d-41ec-8f43-26c70e72eaff"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Gradient of loss w.r.t weight (dw): 6.691762447357178\n",
            "Manual Gradient of loss w.r.t bias (db): 0.998770534992218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using autograd\n",
        "x = torch.tensor(6.7)\n",
        "y = torch.tensor(0.0)\n",
        "# we have to find derivatives dw ,db\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)\n",
        "# input function\n",
        "z = w * x + b\n",
        "y_pred = torch.sigmoid(z)\n",
        "loss = binary_cross_entropy_loss(y_pred, y)\n",
        "print(f\"Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjxXF7N-L2YH",
        "outputId": "2437f93d-4894-4507-8498-c58cf1270182"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 6.701176166534424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backword propagation\n",
        "loss.backward()\n",
        "#print gradient\n",
        "print(f\"Gradient of loss w.r.t weight (dw): {w.grad}\")\n",
        "print(f\"Gradient of loss w.r.t bias (db): {b.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duCSKme6M70k",
        "outputId": "ec220480-d482-4d23-e8bf-c852ca8a4a82"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of loss w.r.t weight (dw): 6.6917619705200195\n",
            "Gradient of loss w.r.t bias (db): 0.9987704753875732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = (x**2).mean()\n",
        "y.backward()\n",
        "print(x.grad)\n",
        "# here partial derivatives happening in terms of 3 values in the tensor\n",
        "# if we run multile time back propagation then gradin will added every time\n",
        "#solution is to clean the grad\n",
        "x.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k5OWuGrOxnA",
        "outputId": "7595f650-e766-45bf-f265-389fc65eb4db"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6667, 1.3333, 2.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##disable gradien tracking in the time of testing"
      ],
      "metadata": {
        "id": "FJCJyuJjVNgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1 - requires_grad_(False)\n",
        "# option 2 - detach()\n",
        "# option 3 - torch.no_grad()\n",
        "\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x ** 2\n",
        "y.backward()\n",
        "print(x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLBDWOMhVZx5",
        "outputId": "ce4895ef-d619-4c99-b59f-34c22aaa49a8"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2., requires_grad=True)\n",
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1 - requires_grad_(False)\n",
        "x.requires_grad_(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlNLfsR9WR_U",
        "outputId": "8b6f631f-f0ee-4923-b4ad-bf2e1bfc63ea"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# option 2 - detach()\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "print(x)\n",
        "# produced new tensor\n",
        "z = x.detach()\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S6-gePjXO2N",
        "outputId": "088e3357-5062-4d48-e05c-17aead9acb1b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2., requires_grad=True)\n",
            "tensor(2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # option 3 - torch.no_grad()\n",
        "x1 = torch.tensor(2.0, requires_grad=True)\n",
        "print(x1)\n",
        "with torch.no_grad():\n",
        "  y = x1 ** 2\n",
        "  print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H2FNYd0ZsKP",
        "outputId": "eb6588dc-87bd-4165-fdbb-7e1597417dcd"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2., requires_grad=True)\n",
            "tensor(4.)\n"
          ]
        }
      ]
    }
  ]
}